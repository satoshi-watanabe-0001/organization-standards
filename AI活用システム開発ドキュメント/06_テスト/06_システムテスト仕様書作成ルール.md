# システムテスト仕様書作成ルール

## 1. 基本情報

### 1.1 ドキュメント名
システムテスト仕様書（System Test Specification）

### 1.2 目的
- システム全体が要件定義で定義された機能・非機能要件を満たすことを検証する
- エンドツーエンド（E2E）のシナリオテストを実施する
- 性能、セキュリティ、可用性等の非機能要件を検証する
- 本番環境に近い条件下でシステムの動作を確認する

### 1.3 対象読者
- テストエンジニア
- 品質保証担当者
- プロジェクトマネージャー
- システムアーキテクト

### 1.4 関連成果物
- **前提**：要件定義書、非機能要件定義書、結合テスト報告書
- **参照**：システム構成図、アーキテクチャ設計書、セキュリティ設計書
- **出力先**：システムテスト報告書、受入テスト仕様書

---

## 2. 作成タイミングと前提条件

### 2.1 作成タイミング
- 結合テストが完了した後
- システムテスト環境が構築された後
- システムテスト実施の2～3週間前

### 2.2 前提条件
- 結合テストが合格している
- システムテスト環境（本番相当環境）が準備されている
- 要件定義書、非機能要件定義書が確定している
- テストデータ（本番相当のデータ量）が準備できる

### 2.3 標準作成期間
- 小規模システム：1～2週間
- 中規模システム：2～3週間
- 大規模システム：3～6週間

---

## 3. ドキュメント構成

### 3.1 必須セクション

#### 3.1.1 テスト方針
- システムテストの目的・範囲
- テスト観点（機能、性能、セキュリティ、可用性、運用性）
- テスト環境（本番相当環境の構成）
- テスト実施スケジュール

#### 3.1.2 機能テスト
- ユースケースシナリオベースのE2Eテスト
- 業務フロー全体の動作確認
- 画面遷移、データ連携の確認

#### 3.1.3 非機能テスト
- **性能テスト**：レスポンスタイム、スループット
- **負荷テスト**：同時接続数、ピーク時の動作
- **ストレステスト**：限界性能、障害時の挙動
- **セキュリティテスト**：脆弱性診断、侵入テスト
- **可用性テスト**：障害復旧、フェイルオーバー
- **運用性テスト**：バックアップ、リストア、ログ出力

#### 3.1.4 テストケース一覧
- テストケースID
- テストシナリオ名
- テスト観点（機能／非機能）
- 前提条件
- テスト手順
- 期待結果
- 優先度

#### 3.1.5 完了基準
- テストケース実施率（100%）
- 合格率（95%以上）
- Critical／High不具合（0件）
- 性能要件達成率（100%）

---

## 4. 記載ルール

### 4.1 機能テスト（E2E）の表記規則

```markdown
## 機能テスト：ユーザー登録～注文完了シナリオ

### シナリオ概要
新規ユーザーがアカウント登録し、商品を検索、カートに追加、決済を完了するまでの一連の業務フローを検証する。

### テストケース一覧

| テストケースID | テストシナリオ | テスト観点 | 優先度 |
|----------------|----------------|------------|--------|
| ST_E2E_001 | 新規ユーザー登録→ログイン→商品検索→注文→決済成功 | 正常系E2E | 高 |
| ST_E2E_002 | ログイン→在庫切れ商品→エラーメッセージ表示 | 異常系E2E | 中 |
| ST_E2E_003 | 決済失敗→注文キャンセル→在庫復元 | 異常系E2E | 高 |
| ST_E2E_004 | 複数商品カート→クーポン適用→合計金額再計算 | 正常系E2E | 中 |

### テストケース詳細: ST_E2E_001

**テストシナリオ**: 新規ユーザー登録→ログイン→商品検索→注文→決済成功

**前提条件**:
- データベースが初期状態（マスターデータのみ）
- 商品マスターに「商品A（在庫10）」が登録されている
- 決済API（モック）が正常動作

**テスト手順**:

1. **ユーザー登録**
   - トップページ（/）にアクセス
   - 「新規登録」ボタンをクリック
   - 登録フォームに入力
     - メール：test@example.com
     - パスワード：Pass123!
     - 氏名：テスト太郎
   - 「登録」ボタンをクリック

2. **ログイン**
   - ウェルカムメール受信を確認
   - ログイン画面（/login）にアクセス
   - メール、パスワードを入力
   - 「ログイン」ボタンをクリック

3. **商品検索**
   - トップページにリダイレクト
   - 検索ボックスに「商品A」を入力
   - 検索結果に「商品A」が表示される

4. **カート追加**
   - 「商品A」の詳細ページに遷移
   - 数量「2」を選択
   - 「カートに追加」ボタンをクリック

5. **注文確定**
   - カートページ（/cart）に遷移
   - 商品「商品A × 2」、合計金額が表示される
   - 「注文確定」ボタンをクリック

6. **決済**
   - 決済画面（/checkout）に遷移
   - クレジットカード情報を入力
   - 「決済」ボタンをクリック

7. **注文完了**
   - 注文完了画面（/order/complete）に遷移
   - 注文番号が表示される
   - 注文確認メールが送信される

**期待結果**:

| ステップ | 期待結果 |
|----------|----------|
| 1. ユーザー登録 | - 登録成功メッセージ表示<br>- usersテーブルに1件追加<br>- ウェルカムメール送信 |
| 2. ログイン | - トップページにリダイレクト<br>- ヘッダーに「テスト太郎さん」と表示 |
| 3. 商品検索 | - 検索結果に「商品A」が表示<br>- 価格、在庫数が正しく表示 |
| 4. カート追加 | - カートアイコンに「2」のバッジ表示<br>- 「カートに追加しました」メッセージ |
| 5. 注文確定 | - カートページに「商品A × 2」表示<br>- 合計金額が正しく計算される |
| 6. 決済 | - 決済API呼び出し成功<br>- 「決済処理中...」ローディング表示 |
| 7. 注文完了 | - 注文番号「ORD-000001」表示<br>- 注文確認メール送信<br>- 在庫が8に減少<br>- ordersテーブルに1件追加 |

**実施時間**: 約5分（手動実施）、約30秒（自動化）
```

### 4.2 非機能テスト（性能）の表記規則

```markdown
## 非機能テスト：性能テスト

### 性能要件

| 項目 | 目標値 | 測定方法 |
|------|--------|----------|
| レスポンスタイム（平均） | 2秒以内 | Apache JMeter |
| レスポンスタイム（95%ile） | 3秒以内 | Apache JMeter |
| スループット | 100 TPS以上 | Apache JMeter |
| 同時接続数 | 500ユーザー | Apache JMeter |
| CPU使用率 | 70%以下 | CloudWatch |
| メモリ使用率 | 80%以下 | CloudWatch |

### テストケース: ST_PERF_001（通常負荷テスト）

**テストシナリオ**: 通常業務時間帯の負荷を想定したテスト

**負荷条件**:
- 同時ユーザー数：200
- テスト時間：30分
- シナリオ：
  - 商品検索（40%）
  - 商品詳細閲覧（30%）
  - カート追加（20%）
  - 注文確定（10%）

**測定項目**:
- 各APIのレスポンスタイム（平均、中央値、95%ile、最大値）
- スループット（リクエスト数／秒）
- エラー率
- サーバーリソース使用率（CPU、メモリ、ネットワーク）

**期待結果**:

| API | 平均レスポンスタイム | 95%ile | スループット | エラー率 |
|-----|----------------------|--------|--------------|----------|
| GET /api/products | < 500ms | < 1000ms | > 50 req/s | < 0.1% |
| GET /api/products/{id} | < 300ms | < 800ms | > 30 req/s | < 0.1% |
| POST /api/cart | < 1000ms | < 2000ms | > 20 req/s | < 0.1% |
| POST /api/orders | < 2000ms | < 3000ms | > 10 req/s | < 0.1% |

**JMeterテスト設定**:
```xml
<ThreadGroup>
  <stringProp name="ThreadGroup.num_threads">200</stringProp>
  <stringProp name="ThreadGroup.ramp_time">60</stringProp>
  <stringProp name="ThreadGroup.duration">1800</stringProp>
</ThreadGroup>
```

### テストケース: ST_PERF_002（ピーク負荷テスト）

**テストシナリオ**: セール時等のピーク負荷を想定

**負荷条件**:
- 同時ユーザー数：500
- テスト時間：10分
- シナリオ：商品検索中心

**期待結果**:
- レスポンスタイム（平均）：3秒以内
- エラー率：1%以下
- サーバーダウンしないこと
```

### 4.3 非機能テスト（セキュリティ）の表記規則

```markdown
## 非機能テスト：セキュリティテスト

### セキュリティ要件

| 項目 | 要件 | テスト方法 |
|------|------|------------|
| 認証 | JWT認証、有効期限24時間 | 手動テスト、自動テスト |
| 認可 | ロールベースアクセス制御（RBAC） | 手動テスト |
| SQLインジェクション | 脆弱性なし | OWASP ZAP |
| XSS（クロスサイトスクリプティング） | 脆弱性なし | OWASP ZAP |
| CSRF | トークン検証あり | 手動テスト |
| 通信暗号化 | TLS 1.2以上 | OpenSSL、ブラウザ検証 |
| パスワードハッシュ | bcrypt（コスト10以上） | コードレビュー、DB確認 |

### テストケース: ST_SEC_001（認証テスト）

**テストシナリオ**: JWT認証の動作確認

**テスト項目**:

| 項目 | テスト内容 | 期待結果 |
|------|------------|----------|
| 正常な認証 | 正しいメール・パスワードでログイン | JWTトークン発行、有効期限24時間 |
| 誤ったパスワード | 間違ったパスワードでログイン | 401 Unauthorized、エラーメッセージ |
| トークン有効期限切れ | 25時間後にAPIアクセス | 401 Unauthorized、再ログイン要求 |
| トークン改ざん | 署名を改ざんしたトークンでアクセス | 401 Unauthorized |
| トークンなし | Authorization ヘッダーなしでAPIアクセス | 401 Unauthorized |

### テストケース: ST_SEC_005（SQLインジェクション）

**テストシナリオ**: OWASP ZAPによる自動脆弱性診断

**テスト対象**:
- 全APIエンドポイント
- 特に検索、フィルター機能

**攻撃パターン例**:
```
GET /api/products?name=' OR '1'='1
GET /api/products?name='; DROP TABLE users--
POST /api/login
{
  "email": "admin@example.com' OR '1'='1' --",
  "password": "dummy"
}
```

**期待結果**:
- 全てのパターンで脆弱性が**検出されない**
- SQLインジェクション試行はログに記録される
- 異常なリクエストは400 Bad Requestで拒否される
```

### 4.4 非機能テスト（可用性）の表記規則

```markdown
## 非機能テスト：可用性テスト

### 可用性要件

| 項目 | 要件 | 測定方法 |
|------|------|----------|
| 稼働率 | 99.9%以上（ダウンタイム月間43分以内） | 監視ツール |
| RTO（目標復旧時間） | 1時間以内 | 障害シミュレーション |
| RPO（目標復旧時点） | 5分以内 | バックアップテスト |
| フェイルオーバー時間 | 30秒以内 | 障害シミュレーション |

### テストケース: ST_AVAIL_001（データベースフェイルオーバー）

**テストシナリオ**: マスターDBダウン時のフェイルオーバー動作確認

**前提条件**:
- レプリケーション構成（Master + Slave）
- 自動フェイルオーバー設定済み

**テスト手順**:
1. 通常負荷状態でシステム稼働中（100 TPS）
2. マスターDBを強制停止（`systemctl stop mysql`）
3. フェイルオーバー発生を確認
4. スレーブDBがマスターに昇格
5. アプリケーションがスレーブDBに接続
6. 業務継続を確認

**期待結果**:
- フェイルオーバー時間：**30秒以内**
- ダウンタイム：**30秒以内**
- データ損失：**なし**（同期レプリケーション）
- エラー率：一時的に上昇するが、**5%以内**
- 業務再開：フェイルオーバー後、即座に正常動作

**測定方法**:
```bash
# フェイルオーバー時間の測定
# ログに記録されたタイムスタンプから算出
grep "Failover" /var/log/application.log
# 出力例：
# 2025-10-30 10:00:00 - Master DB connection failed
# 2025-10-30 10:00:28 - Failover completed, connected to Slave DB
# フェイルオーバー時間: 28秒
```
```

---

## 5. 品質基準

### 5.1 チェックリスト

- [ ] 全ての要件定義項目がテストケースでカバーされているか
- [ ] E2Eシナリオが主要な業務フローをカバーしているか
- [ ] 非機能要件（性能、セキュリティ、可用性）のテストケースがあるか
- [ ] テスト環境が本番相当の構成か
- [ ] 性能テストの負荷条件が現実的か
- [ ] セキュリティテストでOWASP Top 10がカバーされているか
- [ ] 完了基準が明確か

### 5.2 レビュー観点

#### 5.2.1 網羅性
- 要件定義書の全項目がトレース可能か
- 非機能要件が全てテストされるか

#### 5.2.2 現実性
- テストシナリオが実業務に即しているか
- 負荷条件が本番環境を想定しているか

#### 5.2.3 測定可能性
- 期待結果が定量的に測定可能か
- 合否判定基準が明確か

### 5.3 承認基準
- テストリーダーによる内容確認
- システムアーキテクトによる非機能要件確認
- プロジェクトマネージャーによる承認

---

## 6. AI作成時の具体的指示

### 6.1 必須項目

1. **E2Eシナリオの具体性**
   - 画面遷移、入力値、期待結果を詳細に記載
   - 業務フロー全体を通したシナリオ

2. **非機能要件の定量化**
   - 性能：レスポンスタイム、スループット（具体的な数値）
   - セキュリティ：脆弱性診断ツール、攻撃パターン
   - 可用性：RTO、RPO、フェイルオーバー時間

3. **測定方法の明示**
   - 使用ツール（JMeter、OWASP ZAP等）
   - 測定手順、設定ファイル例

### 6.2 避けるべき表現

❌ **NG例**：
```markdown
- "システムが正常に動作することを確認"
- "十分な性能が出ることを確認"
- "セキュリティ対策が適切に実施されていることを確認"
```

✅ **OK例**：
```markdown
- "ユーザー登録→ログイン→商品検索→注文→決済の一連の流れが、各ステップで期待結果通りに動作することを確認"
- "同時200ユーザー、30分間の負荷テストで、平均レスポンスタイム2秒以内、エラー率0.1%以下を達成することを確認"
- "OWASP ZAPによる自動診断で、SQLインジェクション、XSS、CSRF等のOWASP Top 10の脆弱性が検出されないことを確認"
```

### 6.3 推奨構成

1. **要件トレーサビリティマトリクスを含める**
   ```markdown
   | 要件ID | 要件名 | テストケースID | 状態 |
   |--------|--------|----------------|------|
   | REQ-001 | ユーザー登録 | ST_E2E_001 | 計画済み |
   | REQ-002 | 商品検索 | ST_E2E_001, ST_PERF_001 | 計画済み |
   ```

2. **テストツールの設定例を含める**
   - JMeterのテストプラン（XML）
   - OWASP ZAPのスキャン設定
   - Seleniumのテストコード例

---

## 7. 関連ドキュメント

### 7.1 参照すべき成果物
- **要件定義書**：機能要件、非機能要件
- **システム構成図**：インフラ構成、ネットワーク
- **結合テスト報告書**：前工程の問題点

### 7.2 次工程で使用される成果物
- **システムテスト報告書**：テスト結果、品質評価
- **受入テスト仕様書**：ユーザー受入テスト
- **リリース判定会議資料**：リリース可否判断

---

## 8. よくある失敗例と対策

| 失敗例 | 原因 | 対策 |
|--------|------|------|
| E2Eシナリオが単体機能のテスト | 結合テストとの区別不明確 | 複数モジュール・画面を跨ぐシナリオを作成 |
| 性能テストの負荷条件が不適切 | 本番環境の想定が甘い | ピーク時の3倍の負荷でテスト |
| セキュリティテストが形骸化 | チェックリストのみ実施 | OWASP ZAP等のツールで実際に診断 |
| テスト環境が本番と異なる | コスト削減 | 性能テストは本番相当環境で実施（クラウドの一時利用等） |
| 非機能要件の期待結果が曖昧 | 定量的な基準なし | 具体的な数値目標を設定（例：レスポンス2秒以内） |
| 可用性テストが未実施 | 障害シミュレーションの難しさ | Chaos Engineering ツール（Chaos Monkey等）を使用 |
| テスト期間が不足 | 見積もりが甘い | システムテストは全工程の20～30%の期間を確保 |

---

**ドキュメントバージョン**: 1.0  
**最終更新日**: 2025-10-30
